{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU4ANuCJfQ0u"
   },
   "source": [
    "## Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlBYXPrr40p_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/camilojd/.local/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm as norm_stat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgdD7BcLfVT0"
   },
   "source": [
    "## Creating Pandas Transapp DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Rz0zE8k6ZE6"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1. Patente\n",
    "2. Sonda (servicio interno que identifica recorrido de manera unica) (variantes)\n",
    "3. Servicio de Usuario (lo que ve el pasajero)\n",
    "4. Dia y hora (UTC). Ultimo dia de Abril y ultimo día de Mayo\n",
    "5. Latitud\n",
    "6. Longitud\n",
    "7. x (UTM)\n",
    "8. y (UTM)\n",
    "9. Distancia en Ruta (desde inicio hasta t)\n",
    "10. Distancia a la ruta (ortogonal a la polilinea)\n",
    "11. Velocidad instantanea (maquina del GPS del bus)\n",
    "12. Operador (codificacion empresa)\n",
    "13. Identificador de expedición (viaje de un lugar a otro)\n",
    "\"\"\"\n",
    "\n",
    "def create_gps(gps_name):\n",
    "    columns = [\"Patente\", \"GPS_COD_SINRUT\", \"idx_user\", \"Date\", \"LAT\", \"LON\", \"x_UTM\", \"y_UTM\", \"dist_rute\", \"dist_to_rute\", \"velocity\", \"idx_empresa\", \"idx_expedition\"]\n",
    "    # GPS Data\n",
    "    df_gps = pd.read_csv(gps_name,header=None,delimiter=\";\")\n",
    "    df_gps.columns = columns\n",
    "    df_gps.index = df_gps[\"Date\"]\n",
    "    df_gps.index = pd.to_datetime(df_gps.index)\n",
    "    return df_gps\n",
    "\n",
    "def create_dict(dict_name):\n",
    "    # Dictionary Data\n",
    "    df_dict = pd.read_csv(dict_name,delimiter=\";\",encoding='latin-1')\n",
    "    df_dict.index = df_dict[\"COD_SINRUT\"]\n",
    "    return df_dict\n",
    "\n",
    "def create_shape(shape_name):\n",
    "    # Shape Data\n",
    "    df_shape = pd.read_csv(shape_name,delimiter=\";\")\n",
    "    df_shape.index = df_shape[\"ROUTE_NAME\"]\n",
    "    return df_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bus(bus_name, is_ida, threshold_to_route, df_dict, df_data):\n",
    "    if is_ida:\n",
    "        cod_sr = df_dict[(df_dict['COD_USUARI'] == '315e') & (df_dict['Route_Name'].str.endswith('I'))][['Route_ID', 'Route_Name', 'COD_USUARI']]\n",
    "    else:\n",
    "        cod_sr = df_dict[(df_dict['COD_USUARI'] == '315e') & (df_dict['Route_Name'].str.endswith('R'))][['Route_ID', 'Route_Name', 'COD_USUARI']]\n",
    "    df = df_data.set_index('GPS_COD_SINRUT').join(cod_sr, how='right').set_index('Date').sort_values(by='Date')\n",
    "    return df[(df[\"dist_to_rute\"] <= threshold_to_route)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BpLmsRPfCCzw"
   },
   "outputs": [],
   "source": [
    "def filter_gps(df_gps, date, bus_shape, patente):\n",
    "    if patente == None:\n",
    "        return df_gps[(df_gps[\"Date\"].str.contains(date)) & (df_gps[\"idx_user\"] == bus_shape) ]\n",
    "    else:\n",
    "        return df_gps[(df_gps[\"Date\"].str.contains(date)) & (df_gps[\"idx_user\"] == bus_shape) & (df_gps[\"Patente\"] == patente) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XUuYGBBECZ8Y"
   },
   "source": [
    "## Create DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GN9CD8yEF3xW"
   },
   "outputs": [],
   "source": [
    "# Parameters to filter\n",
    "date = \"2019-05-02\"\n",
    "bus_name = '315e'\n",
    "ida = True\n",
    "threshold_to_route = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIt7FdV8BTjh"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_data = create_gps(\"./data/{}.gps\".format(date))\n",
    "df_dict = create_dict(\"./data/2019-04-Diccionario_Servicios.csv\")\n",
    "df_shape = create_shape(\"./data/2019-04-ShapeRutas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patente</th>\n",
       "      <th>idx_user</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>x_UTM</th>\n",
       "      <th>y_UTM</th>\n",
       "      <th>dist_rute</th>\n",
       "      <th>dist_to_rute</th>\n",
       "      <th>velocity</th>\n",
       "      <th>idx_empresa</th>\n",
       "      <th>idx_expedition</th>\n",
       "      <th>Route_ID</th>\n",
       "      <th>Route_Name</th>\n",
       "      <th>COD_USUARI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-01 23:57:54</th>\n",
       "      <td>CJRB12</td>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.385679</td>\n",
       "      <td>-70.691641</td>\n",
       "      <td>342656</td>\n",
       "      <td>6304677</td>\n",
       "      <td>13052</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>62</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01 23:57:57</th>\n",
       "      <td>FLXH99</td>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.363410</td>\n",
       "      <td>-70.766278</td>\n",
       "      <td>335671</td>\n",
       "      <td>6307031</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>95</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01 23:58:01</th>\n",
       "      <td>FLXH94</td>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.363583</td>\n",
       "      <td>-70.766153</td>\n",
       "      <td>335683</td>\n",
       "      <td>6307012</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>72</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01 23:58:07</th>\n",
       "      <td>FLXH10</td>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.370171</td>\n",
       "      <td>-70.698638</td>\n",
       "      <td>341977</td>\n",
       "      <td>6306386</td>\n",
       "      <td>11213</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>111</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01 23:58:11</th>\n",
       "      <td>FLXH14</td>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.355752</td>\n",
       "      <td>-70.738904</td>\n",
       "      <td>338204</td>\n",
       "      <td>6307923</td>\n",
       "      <td>3637</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "      <td>97</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Patente idx_user        LAT        LON   x_UTM    y_UTM  \\\n",
       "Date                                                                          \n",
       "2019-05-01 23:57:54  CJRB12    315eI -33.385679 -70.691641  342656  6304677   \n",
       "2019-05-01 23:57:57  FLXH99    315eI -33.363410 -70.766278  335671  6307031   \n",
       "2019-05-01 23:58:01  FLXH94    315eI -33.363583 -70.766153  335683  6307012   \n",
       "2019-05-01 23:58:07  FLXH10    315eI -33.370171 -70.698638  341977  6306386   \n",
       "2019-05-01 23:58:11  FLXH14    315eI -33.355752 -70.738904  338204  6307923   \n",
       "\n",
       "                     dist_rute  dist_to_rute  velocity  idx_empresa  \\\n",
       "Date                                                                  \n",
       "2019-05-01 23:57:54      13052             3        45           16   \n",
       "2019-05-01 23:57:57          0            59         0           16   \n",
       "2019-05-01 23:58:01          0            37         0           16   \n",
       "2019-05-01 23:58:07      11213             1        48           16   \n",
       "2019-05-01 23:58:11       3637             0        40           16   \n",
       "\n",
       "                     idx_expedition  Route_ID Route_Name COD_USUARI  \n",
       "Date                                                                 \n",
       "2019-05-01 23:57:54              62      9183      315eI       315e  \n",
       "2019-05-01 23:57:57              95      9183      315eI       315e  \n",
       "2019-05-01 23:58:01              72      9183      315eI       315e  \n",
       "2019-05-01 23:58:07             111      9183      315eI       315e  \n",
       "2019-05-01 23:58:11              97      9183      315eI       315e  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select bus\n",
    "df_gps = extract_bus(bus_name, ida, threshold_to_route, df_dict, df_data) \n",
    "df_gps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2ea9ivdH6bX"
   },
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4m_0FPH77JdU"
   },
   "outputs": [],
   "source": [
    "columns_filter = [\"Patente\",\"x_UTM\",\"y_UTM\",\"velocity\",\"dist_rute\"]\n",
    "bus_idx = df_gps['idx_user'].unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wGhf1xZfH8FC"
   },
   "source": [
    "## First step: Sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0ocd_h8VK1iy",
    "outputId": "9948b696-ce3b-47fb-f595-da3c6f1862be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X-Coordinate</th>\n",
       "      <th>Y-Coordinate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>345389</td>\n",
       "      <td>6299941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>345384</td>\n",
       "      <td>6299945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>338181</td>\n",
       "      <td>6307925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345660</td>\n",
       "      <td>6299306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>346255</td>\n",
       "      <td>6298160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X-Coordinate  Y-Coordinate\n",
       "0        345389       6299941\n",
       "1        345384       6299945\n",
       "2        338181       6307925\n",
       "3        345660       6299306\n",
       "4        346255       6298160"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of samples\n",
    "n_samples = 300\n",
    "n_samples = min(len(df_shape.loc[bus_idx]), n_samples)\n",
    "\n",
    "sample_points = df_shape.loc[bus_idx].sample(n_samples,replace=True)[[\"X-Coordinate\", \"Y-Coordinate\"]].reset_index().drop('ROUTE_NAME',axis=1)\n",
    "print('Number of samples:', sample_points.shape[0])\n",
    "sample_points.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "76Z0clwwH--s"
   },
   "source": [
    "## Second step: Search buses in sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjYVjk86SNIU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buses in sample points: 278\n",
      "Number of samples left: 278\n"
     ]
    }
   ],
   "source": [
    "# Search buses which goes through sample points\n",
    "buses_sample_points = []\n",
    "for i, sample in sample_points.iterrows():\n",
    "    epsilon = 0.1\n",
    "    df_epsilon = df_gps[(df_gps[\"x_UTM\"] - sample[0] <= epsilon) & (df_gps[\"y_UTM\"] - sample[1] <= epsilon)]\n",
    "    if(df_epsilon.empty):\n",
    "        sample_points.drop(i, inplace=True)\n",
    "        continue\n",
    "    #while(df_epsilon.empty):\n",
    "    #    epsilon *= 10\n",
    "    #    df_epsilon = df_gps[(df_gps[\"x_UTM\"] - sample[0] <= epsilon) & (df_gps[\"y_UTM\"] - sample[1] <= epsilon)]\n",
    "    buses_sample_points.append(df_epsilon)\n",
    "print('Buses in sample points:', len(buses_sample_points))\n",
    "print('Number of samples left:', sample_points.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buses_patentes_points = [buses_point.set_index(['Patente', buses_point.index]).sort_index() for buses_point in buses_sample_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>idx_user</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>x_UTM</th>\n",
       "      <th>y_UTM</th>\n",
       "      <th>dist_rute</th>\n",
       "      <th>dist_to_rute</th>\n",
       "      <th>velocity</th>\n",
       "      <th>idx_empresa</th>\n",
       "      <th>idx_expedition</th>\n",
       "      <th>Route_ID</th>\n",
       "      <th>Route_Name</th>\n",
       "      <th>COD_USUARI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Patente</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLXH94</th>\n",
       "      <th>2019-05-02 15:47:09</th>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.428738</td>\n",
       "      <td>-70.663178</td>\n",
       "      <td>345380</td>\n",
       "      <td>6299945</td>\n",
       "      <td>18811</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>78</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLXJ98</th>\n",
       "      <th>2019-05-02 11:44:59</th>\n",
       "      <td>315eI</td>\n",
       "      <td>-33.428737</td>\n",
       "      <td>-70.663210</td>\n",
       "      <td>345377</td>\n",
       "      <td>6299945</td>\n",
       "      <td>18809</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>92</td>\n",
       "      <td>9183</td>\n",
       "      <td>315eI</td>\n",
       "      <td>315e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            idx_user        LAT        LON   x_UTM    y_UTM  \\\n",
       "Patente Date                                                                  \n",
       "FLXH94  2019-05-02 15:47:09    315eI -33.428738 -70.663178  345380  6299945   \n",
       "FLXJ98  2019-05-02 11:44:59    315eI -33.428737 -70.663210  345377  6299945   \n",
       "\n",
       "                             dist_rute  dist_to_rute  velocity  idx_empresa  \\\n",
       "Patente Date                                                                  \n",
       "FLXH94  2019-05-02 15:47:09      18811             2        48           16   \n",
       "FLXJ98  2019-05-02 11:44:59      18809             0        48           16   \n",
       "\n",
       "                             idx_expedition  Route_ID Route_Name COD_USUARI  \n",
       "Patente Date                                                                 \n",
       "FLXH94  2019-05-02 15:47:09              78      9183      315eI       315e  \n",
       "FLXJ98  2019-05-02 11:44:59              92      9183      315eI       315e  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(buses_patentes_points))\n",
    "buses_patentes_points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5A1BP52dIA4j"
   },
   "source": [
    "## Third step: Create dist_point and target_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SDHmbZWN801a",
    "outputId": "eaaf3480-c1d8-4ca5-fa5f-bbff944f74ca",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67d3a7fa4cc4664a198685b39428105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "440.2275252342224\n"
     ]
    }
   ],
   "source": [
    "# Select number of min counts for every travel\n",
    "n_min_travel = 20\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "buses_expeditions = []\n",
    "# For every point and buses that arrive to point \n",
    "for point, buses_point in tqdm(zip(sample_points.values, buses_patentes_points),total=len(sample_points)):\n",
    "    #buses_expeditions = []\n",
    "    # For every expedition\n",
    "    for idx_exp in buses_point['idx_expedition'].unique():\n",
    "        patentes_expedition = buses_point[buses_point['idx_expedition'] == idx_exp].index.get_level_values(0).unique()\n",
    "        # For every patent\n",
    "        for patente in patentes_expedition:\n",
    "            expedition = df_gps[(df_gps['idx_expedition'] == idx_exp) & (df_gps['Patente'] == patente)]\n",
    "            bus_point = buses_point[(buses_point['idx_expedition'] == idx_exp) & (buses_point.index.get_level_values(0) == patente)]\n",
    "            bus_point[\"dist_point\"] = np.linalg.norm(bus_point[[\"x_UTM\",\"y_UTM\"]].values - point, axis=1)\n",
    "            end_time_expedition = bus_point['dist_point'].idxmin()[1]\n",
    "            expedition_end = expedition[expedition.index.get_level_values(0) <= end_time_expedition]\n",
    "            # Check if n_min\n",
    "            if expedition_end.shape[0] <= n_min_travel:\n",
    "                continue\n",
    "            # Distance Polyline\n",
    "            expedition_end[\"dist_target\"] = abs(expedition_end['dist_rute'].iloc[-1] - expedition_end['dist_rute'])\n",
    "\n",
    "            # Create target time in seconds\n",
    "            target = [((pd.to_datetime(expedition_end.index.get_level_values(0)[-1]) - pd.to_datetime(start_time)).seconds//60)%60 for start_time in expedition_end.index.get_level_values(0)]\n",
    "            expedition_end[\"target_time\"] = target\n",
    "\n",
    "            if (not expedition_end['target_time'].is_monotonic_decreasing) or (not expedition_end['dist_target'].is_monotonic_decreasing):\n",
    "                continue\n",
    "\n",
    "            if (len(expedition_end)==0):\n",
    "                continue\n",
    "                \n",
    "            buses_expeditions.append(expedition_end)\n",
    "    #buses_dist_target.append(buses_expeditions)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tCC528iF-I00"
   },
   "source": [
    "# Retrieve and split data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ygM4rvfA3BqD"
   },
   "outputs": [],
   "source": [
    "# Normalize\n",
    "norm = True\n",
    "scaler_filename = \"scaler_LSTM.save\"\n",
    "\n",
    "# Select Data\n",
    "columns = [\"x_UTM\",\"y_UTM\",\"velocity\",\"dist_target\",\"target_time\"]\n",
    "df_data = pd.concat(buses_expeditions)[columns]\n",
    "\n",
    "# Separate data in features and targets\n",
    "X = df_data[columns[:-1]]\n",
    "y = df_data[columns[-1]]\n",
    "\n",
    "# Split Train and Test\n",
    "df_X_train, X_testval, df_y_train, y_testval = train_test_split(X, y, test_size=0.33, shuffle=False)\n",
    "df_X_val, df_X_test, df_y_val, df_y_test = train_test_split(X_testval, y_testval, test_size=0.66, shuffle=False)\n",
    "\n",
    "# Fix dimentions\n",
    "y_train = np.expand_dims(df_y_train,1)\n",
    "y_val = np.expand_dims(df_y_val,1)\n",
    "y_test = np.expand_dims(df_y_test,1)\n",
    "\n",
    "# Scale data\n",
    "if norm:\n",
    "    scaler_x = MinMaxScaler()\n",
    "    X_train = scaler_x.fit_transform(df_X_train)\n",
    "    X_val = scaler_x.transform(df_X_val)\n",
    "    X_test = scaler_x.transform(df_X_test)\n",
    "\n",
    "    # Save Scaler\n",
    "    #joblib.dump(scaler_x, scaler_filename) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jltY-Gi8JgQh",
    "outputId": "fa5ef91c-0d67-49b2-d639-e3f99ebee3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data (884454, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"df_data\", df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "9xs3ZrfH_u19",
    "outputId": "3bfd1c16-c317-4758-86a2-8b31702f039b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (592584, 4)\n",
      "y_train: (592584, 1)\n",
      "X_val: (99235, 4)\n",
      "y_val: (99235, 1)\n",
      "X_test: (192635, 4)\n",
      "y_test: (192635, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Chsq2MAFvpo"
   },
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QNo8PpuYkdPL",
    "outputId": "b80dd8c8-619b-4297-9f5f-d3a00b1e4aca"
   },
   "outputs": [],
   "source": [
    "# Parameters for learning\n",
    "input_units = 15\n",
    "learning_rate = 0.0001\n",
    "epochs = 500\n",
    "batch_size = 500000\n",
    "patience = 10\n",
    "seq_length = 20 \n",
    "percentile = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 298.5775 - mae: 12.8901 - val_loss: 206.9477 - val_mae: 10.6550\n",
      "Epoch 2/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 215.4419 - mae: 10.8827 - val_loss: 159.8889 - val_mae: 9.6442\n",
      "Epoch 3/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 180.2213 - mae: 10.2802 - val_loss: 142.5911 - val_mae: 9.4908\n",
      "Epoch 4/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 168.3078 - mae: 10.2155 - val_loss: 138.8731 - val_mae: 9.5909\n",
      "Epoch 5/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 165.5178 - mae: 10.2672 - val_loss: 134.1696 - val_mae: 9.3416\n",
      "Epoch 6/500\n",
      "4630/4630 [==============================] - 43s 9ms/step - loss: 150.8791 - mae: 9.4582 - val_loss: 108.1280 - val_mae: 7.9584\n",
      "Epoch 7/500\n",
      "4630/4630 [==============================] - 43s 9ms/step - loss: 128.3323 - mae: 8.3954 - val_loss: 95.4622 - val_mae: 7.3524\n",
      "Epoch 8/500\n",
      "4630/4630 [==============================] - 42s 9ms/step - loss: 115.2606 - mae: 7.8736 - val_loss: 85.2188 - val_mae: 6.9131\n",
      "Epoch 9/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 105.6906 - mae: 7.5056 - val_loss: 79.2482 - val_mae: 6.6751\n",
      "Epoch 10/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 98.1092 - mae: 7.2220 - val_loss: 72.4885 - val_mae: 6.2963\n",
      "Epoch 11/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 92.5749 - mae: 6.9982 - val_loss: 66.7895 - val_mae: 5.9338\n",
      "Epoch 12/500\n",
      "4630/4630 [==============================] - 40s 9ms/step - loss: 87.8150 - mae: 6.8192 - val_loss: 63.5052 - val_mae: 5.7224\n",
      "Epoch 13/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 84.2190 - mae: 6.6635 - val_loss: 61.0856 - val_mae: 5.6507\n",
      "Epoch 14/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 81.0124 - mae: 6.5206 - val_loss: 59.6270 - val_mae: 5.5403\n",
      "Epoch 15/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 78.4948 - mae: 6.4141 - val_loss: 58.4946 - val_mae: 5.5132\n",
      "Epoch 16/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 76.4377 - mae: 6.3196 - val_loss: 56.1078 - val_mae: 5.3101\n",
      "Epoch 17/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 74.6562 - mae: 6.2282 - val_loss: 56.2453 - val_mae: 5.3037\n",
      "Epoch 18/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 72.8833 - mae: 6.1431 - val_loss: 56.2883 - val_mae: 5.3737\n",
      "Epoch 19/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 71.4580 - mae: 6.0714 - val_loss: 56.2631 - val_mae: 5.3015\n",
      "Epoch 20/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 70.3523 - mae: 6.0101 - val_loss: 55.9255 - val_mae: 5.3341\n",
      "Epoch 21/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 69.4043 - mae: 5.9555 - val_loss: 55.0337 - val_mae: 5.2723\n",
      "Epoch 22/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 68.6114 - mae: 5.9110 - val_loss: 53.3613 - val_mae: 5.1314\n",
      "Epoch 23/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 67.4835 - mae: 5.8595 - val_loss: 53.0925 - val_mae: 5.1260\n",
      "Epoch 24/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 66.7908 - mae: 5.8160 - val_loss: 53.5163 - val_mae: 5.1655\n",
      "Epoch 25/500\n",
      "4630/4630 [==============================] - 41s 9ms/step - loss: 66.2671 - mae: 5.7880 - val_loss: 48.7138 - val_mae: 4.9131\n",
      "Epoch 26/500\n",
      "4630/4630 [==============================] - 43s 9ms/step - loss: 65.7581 - mae: 5.7613 - val_loss: 51.0170 - val_mae: 5.0287\n",
      "Epoch 27/500\n",
      "4630/4630 [==============================] - 43s 9ms/step - loss: 65.3398 - mae: 5.7358 - val_loss: 51.5950 - val_mae: 5.0262\n",
      "Epoch 28/500\n",
      "4630/4630 [==============================] - 44s 10ms/step - loss: 64.6412 - mae: 5.6963 - val_loss: 49.2209 - val_mae: 4.9407\n",
      "Epoch 29/500\n",
      " 832/4630 [====>.........................] - ETA: 35s - loss: 65.3130 - mae: 5.7134"
     ]
    }
   ],
   "source": [
    "# Time Sequences\n",
    "data_gen_train = TimeseriesGenerator(X_train, y_train.squeeze(), length=seq_length)\n",
    "data_gen_val = TimeseriesGenerator(X_val, y_val.squeeze(), length=seq_length, batch_size=batch_size)\n",
    "data_gen_test = TimeseriesGenerator(X_test, y_test.squeeze(), length=seq_length, batch_size=batch_size)\n",
    "\n",
    "# Model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(input_units, return_sequences=True, activation='relu', dropout=0.2, recurrent_dropout=0.2, \n",
    "                input_shape=(data_gen_train[0][0].shape[1], data_gen_train[0][0].shape[2])))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(LSTM(10))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Dense(1, activation='relu'))\n",
    "\n",
    "# Compilation\n",
    "optim = optimizers.Adam(lr=learning_rate)\n",
    "lstm.compile(loss='mse', optimizer=optim, metrics=['mae'])\n",
    "# Train\n",
    "earlyStop = EarlyStopping(monitor=\"val_loss\",verbose=2,mode='auto',patience=patience,restore_best_weights=False)\n",
    "lstm_history = lstm.fit_generator(data_gen_train, epochs=epochs, validation_data=data_gen_val, callbacks=[earlyStop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and val Loss\n",
    "train_loss = lstm_history.history['loss']\n",
    "val_loss = lstm_history.history['val_loss']\n",
    "loss_fig = plt.figure()\n",
    "loss_title = 'Model Train-Test Loss MSE'\n",
    "\n",
    "loss_fig = plt.figure()\n",
    "plt.plot(np.arange(1, len(train_loss) + 1), train_loss,label=\"train\",alpha=0.5)\n",
    "plt.plot(np.arange(1, len(val_loss) + 1), val_loss,label=\"validation\",alpha=0.5)\n",
    "plt.title(loss_title)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Train and val accuracy\n",
    "train_loss = lstm_history.history['mae']\n",
    "val_loss = lstm_history.history['val_mae']\n",
    "loss_fig = plt.figure()\n",
    "loss_title = 'Model Train-Test Loss MAE'\n",
    "\n",
    "loss_fig = plt.figure()\n",
    "plt.plot(np.arange(1, len(train_loss) + 1), train_loss,label=\"train\",alpha=0.5)\n",
    "plt.plot(np.arange(1, len(val_loss) + 1), val_loss,label=\"validation\",alpha=0.5)\n",
    "plt.title(loss_title)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC-Dropout prediction\n",
    "lstm_mcdroput = K.function([lstm.inputs, K.learning_phase()], lstm.outputs)\n",
    "lstm_mcdropout_pred = []\n",
    "for _ in tqdm(range(100)):\n",
    "    mcdropout_pred = lstm_mcdroput([data_gen_test[0][0]] + [1.])[0].squeeze()\n",
    "    lstm_mcdropout_pred.append(np.pad(mcdropout_pred, (seq_length,0), 'constant', constant_values=0))\n",
    "lstm_mcdropout_pred = np.array(lstm_mcdropout_pred).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "lstm_pred = np.pad(lstm.predict_generator(data_gen_test).squeeze(), (seq_length,0), 'constant', constant_values=0)\n",
    "y_pred = pd.DataFrame(np.percentile(lstm_mcdropout_pred, q=percentile, axis=0),index=df_y_test.index, columns=['pred']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aI5NKXMXGHrB"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lim1 = 3000\n",
    "x_lim2 = 6000\n",
    "# Plot LSTM Prediction\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.plot(df_y_test.values, label='true')\n",
    "plt.plot(lstm_pred, label='predicted')\n",
    "plt.legend(loc='best', prop={'size': 13})\n",
    "plt.title('LSTM Failure Time Prediction')\n",
    "plt.ylabel('target_time')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(x_lim1, x_lim2)\n",
    "#plt.savefig('f1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot LSTM MC-Dropout (mean +- 2*std)\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.plot(df_y_test.values, label='true')\n",
    "plt.plot(lstm_mcdropout_pred.mean(axis=0), label='predicted mean')\n",
    "plt.fill_between(range(0, X_test.shape[0]), lstm_mcdropout_pred.mean(axis=0) - 2*lstm_mcdropout_pred.std(axis=0),\n",
    "                 lstm_mcdropout_pred.mean(axis=0) + 2*lstm_mcdropout_pred.std(axis=0), color='orange', alpha='0.5')\n",
    "plt.legend(loc='best', prop={'size': 13})\n",
    "plt.title('MC-Dropout LSTM Failure Time Prediction')\n",
    "plt.ylabel('target_time')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(x_lim1, x_lim2)\n",
    "#plt.ylim(-0.05, 1.05)\n",
    "#plt.savefig('f1.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Plot MLP MC-Dropout Percentile\n",
    "plt.figure(figsize=(18,4))\n",
    "plt.plot(df_y_test.values, label='true')\n",
    "plt.plot(np.percentile(lstm_mcdropout_pred, q=percentile, axis=0), label='Percentile {}'.format(percentile))\n",
    "plt.legend(loc='best', prop={'size': 13})\n",
    "plt.title('MC-Dropout LSTM Failure Time Prediction')\n",
    "plt.ylabel('target_time')\n",
    "plt.xlabel('Step')\n",
    "plt.xlim(x_lim1, x_lim2)\n",
    "plt.savefig('mc_drop.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "z0yQ9PWyJtL2",
    "outputId": "1afb0de3-3494-489f-9270-049ef309f9d5"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "MSE = mean_squared_error(y_pred.values, df_y_test.values)\n",
    "error = y_pred.values.squeeze() - df_y_test.values\n",
    "\n",
    "norm_fitted = norm_stat.fit(error)\n",
    "\n",
    "# Distribution Error Histogram\n",
    "hist_fig, ax = plt.subplots()\n",
    "ax = sns.distplot(error,fit=norm_stat,label= r\"$(\\mu,\\sigma)=$ (\" + str('%.3f'%norm_fitted[0]) + \",\" + str('%.3f'%norm_fitted[1]) + \")\"  )\n",
    "hist_title = 'Distribution Error Fitted using ' + ', '.join(columns) + ' as variables'+\", norm=\"+str(norm)\n",
    "plt.title(hist_title)\n",
    "plt.xlabel(\"Prediction Error\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "#hist_fig.savefig(\"./results/MLP/\"+hist_title+\" norm=\"+str(norm)+\".png\", bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Error Distribution Norm Fitted parameters (mu,sigma):\", norm_stat.fit(error))\n",
    "print(\"MSE:\", MSE)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CC5214 - Transapp Modelo 2 LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
